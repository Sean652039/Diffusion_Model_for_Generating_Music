{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9cc5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusers[torch]\n",
      "  Downloading diffusers-0.31.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from diffusers[torch]) (6.11.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from diffusers[torch]) (3.16.1)\n",
      "Collecting huggingface-hub>=0.23.2 (from diffusers[torch])\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from diffusers[torch]) (1.26.4)\n",
      "Collecting regex!=2019.12.17 (from diffusers[torch])\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from diffusers[torch]) (2.32.3)\n",
      "Collecting safetensors>=0.3.1 (from diffusers[torch])\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from diffusers[torch]) (11.0.0)\n",
      "Requirement already satisfied: torch<2.5.0,>=1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from diffusers[torch]) (2.2.2)\n",
      "Collecting accelerate>=0.31.0 (from diffusers[torch])\n",
      "  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate>=0.31.0->diffusers[torch]) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate>=0.31.0->diffusers[torch]) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate>=0.31.0->diffusers[torch]) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers[torch]) (2024.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers[torch]) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers[torch]) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<2.5.0,>=1.4->diffusers[torch]) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<2.5.0,>=1.4->diffusers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<2.5.0,>=1.4->diffusers[torch]) (3.1.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata->diffusers[torch]) (3.20.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->diffusers[torch]) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->diffusers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->diffusers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->diffusers[torch]) (2024.8.30)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->accelerate>=0.31.0->diffusers[torch]) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch<2.5.0,>=1.4->diffusers[torch]) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch<2.5.0,>=1.4->diffusers[torch]) (1.3.0)\n",
      "Downloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Downloading diffusers-0.31.0-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, huggingface-hub, diffusers, accelerate\n",
      "Successfully installed accelerate-1.1.1 diffusers-0.31.0 huggingface-hub-0.26.2 regex-2024.11.6 safetensors-0.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "927e2d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from diffusers import UNet2DModel, DDPMScheduler\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59f5bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1004a5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 24 20:29:53 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM2-16GB           On  |   00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   33C    P0             48W /  300W |    7083MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     11021      C   ...conda3/envs/pytorch_p310/bin/python       7080MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "045b298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"\n",
    "    Get the appropriate device (CUDA, MPS, or CPU)\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    return \"cpu\"\n",
    "\n",
    "\n",
    "class PianoRollDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        # Convert grayscale to RGB while maintaining binary values\n",
    "        gray_image = Image.open(image_path).convert('L')\n",
    "        # Convert to binary image first (0 or 255)\n",
    "        binary_image = gray_image.point(lambda x: 0 if x < 128 else 255, '1')\n",
    "        # Convert to RGB\n",
    "        rgb_image = binary_image.convert('RGB')\n",
    "        image = self.transform(rgb_image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "723c294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(images, path, step):\n",
    "    \"\"\"Save a batch of images during training for monitoring.\"\"\"\n",
    "    images = (images / 2 + 0.5).clamp(0, 1)\n",
    "    # Convert to binary\n",
    "    images = (images > 0.5).float()\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "    # Convert to PIL image\n",
    "    grid_image = torchvision.transforms.ToPILImage()(grid)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    grid_image.save(f\"{path}/sample_{step}.png\")\n",
    "\n",
    "\n",
    "def train_loop(config, model, noise_scheduler, optimizer, train_dataloader, device):\n",
    "    progress_bar = tqdm(total=config[\"num_epochs\"] * len(train_dataloader))\n",
    "    global_step = 0\n",
    "\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        model.train()\n",
    "        for batch in train_dataloader:\n",
    "            clean_images = batch.to(device)\n",
    "            batch_size = clean_images.shape[0]\n",
    "\n",
    "            # Sample noise and add to images\n",
    "            noise = torch.randn(clean_images.shape).to(device)\n",
    "            timesteps = torch.randint(\n",
    "                0, noise_scheduler.config.num_train_timesteps, (batch_size,),\n",
    "                device=device\n",
    "            ).long()\n",
    "            noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "            # Get model prediction\n",
    "            noise_pred = model(noisy_images, timesteps, return_dict=False)[0]\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = F.mse_loss(noise_pred, noise)\n",
    "            print(f\"loss:{loss}\")\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            global_step += 1\n",
    "\n",
    "            # Save sample images periodically\n",
    "            if global_step % config[\"sample_interval\"] == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    # Generate sample images\n",
    "                    sample = torch.randn(8, 3, config[\"image_height\"], config[\"image_width\"]).to(device)\n",
    "                    timesteps = torch.linspace(999, 0, 50).long().to(device)\n",
    "                    for t in timesteps:\n",
    "                        residual = model(sample, t.repeat(8), return_dict=False)[0]\n",
    "                        sample = noise_scheduler.step(residual, t, sample).prev_sample\n",
    "                save_images(sample, config[\"sample_dir\"], global_step)\n",
    "                model.train()\n",
    "\n",
    "            if global_step % config[\"save_interval\"] == 0:\n",
    "                # Save checkpoint\n",
    "                torch.save({\n",
    "                    'step': global_step,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "                }, f\"checkpoint_{global_step}.pt\")\n",
    "\n",
    "        # Save model after each epoch\n",
    "        torch.save(model.state_dict(), f\"model_epoch_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d7017c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Configuration\n",
    "    config = {\n",
    "        \"image_height\": 768,\n",
    "        \"image_width\": 512,\n",
    "        \"batch_size\": 2,\n",
    "        \"num_epochs\": 1,\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"save_interval\": 100,\n",
    "        \"sample_interval\": 1000,  # Interval for generating sample images\n",
    "        \"data_dir\": \"piano_roll_images\",  # Your image directory\n",
    "        \"sample_dir\": \"samples\"  # Directory to save generated samples\n",
    "    }\n",
    "\n",
    "    # Initialize device\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    dataset = PianoRollDataset(config[\"data_dir\"])\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    # Initialize model with 3 input/output channels for RGB\n",
    "    model = UNet2DModel(\n",
    "        sample_size=(config[\"image_height\"], config[\"image_width\"]),\n",
    "        in_channels=3,  # RGB input\n",
    "        out_channels=3,  # RGB output\n",
    "        layers_per_block=1,\n",
    "        block_out_channels=(32, 64, 128),  # Further reduced channels\n",
    "        down_block_types=(\n",
    "            \"DownBlock2D\",\n",
    "            \"DownBlock2D\", \n",
    "            \"DownBlock2D\",\n",
    "        ),\n",
    "        up_block_types=(\n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "        ),\n",
    "    ).to(device)\n",
    "\n",
    "    # Initialize noise scheduler\n",
    "    noise_scheduler = DDPMScheduler(\n",
    "        num_train_timesteps=1000,\n",
    "        beta_start=0.0001,\n",
    "        beta_end=0.02,\n",
    "        beta_schedule=\"linear\"\n",
    "    )\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "    # Train model\n",
    "    train_loop(config, model, noise_scheduler, optimizer, dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94028c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04bb97aa02d4b4d9646b7795f1c9ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:1.1097028255462646\n",
      "loss:1.0769217014312744\n",
      "loss:1.031741738319397\n",
      "loss:1.0278807878494263\n",
      "loss:0.9642127156257629\n",
      "loss:0.9427040815353394\n",
      "loss:0.9079720377922058\n",
      "loss:0.8790071606636047\n",
      "loss:0.8823263049125671\n",
      "loss:0.8238559365272522\n",
      "loss:0.8435823917388916\n",
      "loss:0.7746265530586243\n",
      "loss:0.7508037090301514\n",
      "loss:0.7509687542915344\n",
      "loss:0.7120912671089172\n",
      "loss:0.7170543670654297\n",
      "loss:0.6677703261375427\n",
      "loss:0.6417092084884644\n",
      "loss:0.6230636239051819\n",
      "loss:0.6051941514015198\n",
      "loss:0.5898979306221008\n",
      "loss:0.5724374055862427\n",
      "loss:0.5518147945404053\n",
      "loss:0.5372375845909119\n",
      "loss:0.5228298306465149\n",
      "loss:0.5078498125076294\n",
      "loss:0.5415394902229309\n",
      "loss:0.49455907940864563\n",
      "loss:0.607220470905304\n",
      "loss:0.45511844754219055\n",
      "loss:0.4498027265071869\n",
      "loss:0.4321652054786682\n",
      "loss:0.5000439882278442\n",
      "loss:0.409685879945755\n",
      "loss:0.4003109037876129\n",
      "loss:0.3899511396884918\n",
      "loss:0.3990858495235443\n",
      "loss:0.4028222858905792\n",
      "loss:0.36161813139915466\n",
      "loss:0.37377089262008667\n",
      "loss:0.44119352102279663\n",
      "loss:0.4341203272342682\n",
      "loss:0.41327181458473206\n",
      "loss:0.3435138761997223\n",
      "loss:0.3171381950378418\n",
      "loss:0.33415842056274414\n",
      "loss:0.3061434328556061\n",
      "loss:0.5591715574264526\n",
      "loss:0.31101828813552856\n",
      "loss:0.28668785095214844\n",
      "loss:0.2913406491279602\n",
      "loss:0.2791980803012848\n",
      "loss:0.36106154322624207\n",
      "loss:0.2671641409397125\n",
      "loss:0.26140251755714417\n",
      "loss:0.2618494927883148\n",
      "loss:0.27266597747802734\n",
      "loss:0.25057902932167053\n",
      "loss:0.2488624006509781\n",
      "loss:0.2466779500246048\n",
      "loss:0.25826495885849\n",
      "loss:0.41060560941696167\n",
      "loss:0.24864216148853302\n",
      "loss:0.25273752212524414\n",
      "loss:0.24479876458644867\n",
      "loss:0.29817336797714233\n",
      "loss:0.26351648569107056\n",
      "loss:0.20707061886787415\n",
      "loss:0.2056027501821518\n",
      "loss:0.20143981277942657\n",
      "loss:0.19797547161579132\n",
      "loss:0.21048100292682648\n",
      "loss:0.19170673191547394\n",
      "loss:0.18859726190567017\n",
      "loss:0.18569490313529968\n",
      "loss:0.19302065670490265\n",
      "loss:0.17933323979377747\n",
      "loss:0.17594259977340698\n",
      "loss:0.1752055436372757\n",
      "loss:0.1691858321428299\n",
      "loss:0.16723375022411346\n",
      "loss:0.2767641842365265\n",
      "loss:0.162505105137825\n",
      "loss:0.20327253639698029\n",
      "loss:0.15847693383693695\n",
      "loss:0.1597767025232315\n",
      "loss:0.16039323806762695\n",
      "loss:0.15203797817230225\n",
      "loss:0.15383155643939972\n",
      "loss:0.14597387611865997\n",
      "loss:0.14452488720417023\n",
      "loss:0.14215432107448578\n",
      "loss:0.20041672885417938\n",
      "loss:0.13844461739063263\n",
      "loss:0.185756117105484\n",
      "loss:0.13375326991081238\n",
      "loss:0.258222758769989\n",
      "loss:0.13103236258029938\n",
      "loss:0.14622920751571655\n",
      "loss:0.13269633054733276\n",
      "loss:0.22117175161838531\n",
      "loss:0.17631180584430695\n",
      "loss:0.1624060422182083\n",
      "loss:0.13496239483356476\n",
      "loss:0.1237252950668335\n",
      "loss:0.13261857628822327\n",
      "loss:0.17278772592544556\n",
      "loss:0.18764431774616241\n",
      "loss:0.1291804313659668\n",
      "loss:0.1294807642698288\n",
      "loss:0.13061000406742096\n",
      "loss:0.1122119203209877\n",
      "loss:0.11553356796503067\n",
      "loss:0.12160979211330414\n",
      "loss:0.2589942216873169\n",
      "loss:0.1682761311531067\n",
      "loss:0.11391860991716385\n",
      "loss:0.11327692121267319\n",
      "loss:0.17541058361530304\n",
      "loss:0.3600657284259796\n",
      "loss:0.10428772121667862\n",
      "loss:0.10566455125808716\n",
      "loss:0.10670636594295502\n",
      "loss:0.10201368480920792\n",
      "loss:0.10076502710580826\n",
      "loss:0.507100522518158\n",
      "loss:0.10061661899089813\n",
      "loss:0.1325191706418991\n",
      "loss:0.1578211486339569\n",
      "loss:0.10054829716682434\n",
      "loss:0.1447204202413559\n",
      "loss:0.09518416970968246\n",
      "loss:0.09449291229248047\n",
      "loss:0.09360615164041519\n",
      "loss:0.12466691434383392\n",
      "loss:0.0922621414065361\n",
      "loss:0.09135569632053375\n",
      "loss:0.09643368422985077\n",
      "loss:0.09097211807966232\n",
      "loss:0.08862858265638351\n",
      "loss:0.09053286164999008\n",
      "loss:0.0987028032541275\n",
      "loss:0.11191361397504807\n",
      "loss:0.10032103210687637\n",
      "loss:0.09217675775289536\n",
      "loss:0.11474421620368958\n",
      "loss:0.08459354937076569\n",
      "loss:0.09676602482795715\n",
      "loss:0.22113698720932007\n",
      "loss:0.11351887136697769\n",
      "loss:0.11880668252706528\n",
      "loss:0.1084054559469223\n",
      "loss:0.36967790126800537\n",
      "loss:0.11998780816793442\n",
      "loss:0.0864589586853981\n",
      "loss:0.19461873173713684\n",
      "loss:0.09022369980812073\n",
      "loss:0.09335025399923325\n",
      "loss:0.07938987016677856\n",
      "loss:0.08125625550746918\n",
      "loss:0.14554889500141144\n",
      "loss:0.09352162480354309\n",
      "loss:0.09067379683256149\n",
      "loss:0.1302526742219925\n",
      "loss:0.08285374194383621\n",
      "loss:0.08148086071014404\n",
      "loss:0.3482304811477661\n",
      "loss:0.12963400781154633\n",
      "loss:0.07880573719739914\n",
      "loss:0.09254340082406998\n",
      "loss:0.12173037976026535\n",
      "loss:0.1104649156332016\n",
      "loss:0.15238888561725616\n",
      "loss:0.07843352109193802\n",
      "loss:0.0930769070982933\n",
      "loss:0.07562537491321564\n",
      "loss:0.09068801254034042\n",
      "loss:0.07327871769666672\n",
      "loss:0.08880820870399475\n",
      "loss:0.07392548024654388\n",
      "loss:0.10281968116760254\n",
      "loss:0.10049133747816086\n",
      "loss:0.1053931787610054\n",
      "loss:0.07685335725545883\n",
      "loss:0.08806236833333969\n",
      "loss:0.08353449404239655\n",
      "loss:0.07262054830789566\n",
      "loss:0.10770145803689957\n",
      "loss:0.0825284793972969\n",
      "loss:0.10287266224622726\n",
      "loss:0.07822711765766144\n",
      "loss:0.07298461347818375\n",
      "loss:0.07860860973596573\n",
      "loss:0.0749221220612526\n",
      "loss:0.08147655427455902\n",
      "loss:0.06751587986946106\n",
      "loss:0.08343023806810379\n",
      "loss:0.06669878214597702\n",
      "loss:0.06638402491807938\n",
      "loss:0.06797712296247482\n",
      "loss:0.07341958582401276\n",
      "loss:0.06674566864967346\n",
      "loss:0.06549755483865738\n",
      "loss:0.09065359085798264\n",
      "loss:0.06705261021852493\n",
      "loss:0.06838319450616837\n",
      "loss:0.08414153009653091\n",
      "loss:0.08445680886507034\n",
      "loss:0.09326527267694473\n",
      "loss:0.0659063309431076\n",
      "loss:0.0700223296880722\n",
      "loss:0.08191715180873871\n",
      "loss:0.07443507760763168\n",
      "loss:0.06660468876361847\n",
      "loss:0.06604743748903275\n",
      "loss:0.06151309236884117\n",
      "loss:0.07024519145488739\n",
      "loss:0.07312432676553726\n",
      "loss:0.06724116951227188\n",
      "loss:0.09060559421777725\n",
      "loss:0.09684482961893082\n",
      "loss:0.06819114834070206\n",
      "loss:0.06010544300079346\n",
      "loss:0.06105293706059456\n",
      "loss:0.11651787906885147\n",
      "loss:0.061453502625226974\n",
      "loss:0.06096351146697998\n",
      "loss:0.0658554807305336\n",
      "loss:0.05981932953000069\n",
      "loss:0.06779089570045471\n",
      "loss:0.061387188732624054\n",
      "loss:0.05805829539895058\n",
      "loss:0.1262493133544922\n",
      "loss:0.058311622589826584\n",
      "loss:0.06254439800977707\n",
      "loss:0.05720440670847893\n",
      "loss:0.0659000501036644\n",
      "loss:0.10363247990608215\n",
      "loss:0.05691225081682205\n",
      "loss:0.06107111647725105\n",
      "loss:0.059007126837968826\n",
      "loss:0.06804209202528\n",
      "loss:0.060390692204236984\n",
      "loss:0.05560945346951485\n",
      "loss:0.11007314175367355\n",
      "loss:0.0643356591463089\n",
      "loss:0.056013744324445724\n",
      "loss:0.054761964827775955\n",
      "loss:0.08668360859155655\n",
      "loss:0.054397642612457275\n",
      "loss:0.054647255688905716\n",
      "loss:0.06063983216881752\n",
      "loss:0.05381300672888756\n",
      "loss:0.054988618940114975\n",
      "loss:0.07668004930019379\n",
      "loss:0.053698889911174774\n",
      "loss:0.0644613653421402\n",
      "loss:0.05301891639828682\n",
      "loss:0.06091936305165291\n",
      "loss:0.06109629198908806\n",
      "loss:0.05301004275679588\n",
      "loss:0.08155464380979538\n",
      "loss:0.05243091657757759\n",
      "loss:0.058362748473882675\n",
      "loss:0.06091343238949776\n",
      "loss:0.08317838609218597\n",
      "loss:0.051122356206178665\n",
      "loss:0.06145673990249634\n",
      "loss:0.0943547859787941\n",
      "loss:0.15051929652690887\n",
      "loss:0.06653376668691635\n",
      "loss:0.06387702375650406\n",
      "loss:0.06584574282169342\n",
      "loss:0.059657614678144455\n",
      "loss:0.05259700119495392\n",
      "loss:0.08495739102363586\n",
      "loss:0.10989382117986679\n",
      "loss:0.05432608723640442\n",
      "loss:0.05025435984134674\n",
      "loss:0.04986715316772461\n",
      "loss:0.05865402892231941\n",
      "loss:0.049740005284547806\n",
      "loss:0.08229175955057144\n",
      "loss:0.04989631846547127\n",
      "loss:0.07775350660085678\n",
      "loss:0.07063131779432297\n",
      "loss:0.058539167046546936\n",
      "loss:0.093787781894207\n",
      "loss:0.060067884624004364\n",
      "loss:0.05175970494747162\n",
      "loss:0.05278516933321953\n",
      "loss:0.04992334172129631\n",
      "loss:0.05845663323998451\n",
      "loss:0.04831412807106972\n",
      "loss:0.04943035915493965\n",
      "loss:0.0729127898812294\n",
      "loss:0.051044028252363205\n",
      "loss:0.060845546424388885\n",
      "loss:0.05846268683671951\n",
      "loss:0.047186460345983505\n",
      "loss:0.04697452858090401\n",
      "loss:0.4001706540584564\n",
      "loss:0.04700382798910141\n",
      "loss:0.049864333122968674\n",
      "loss:0.06005745381116867\n",
      "loss:0.06832969188690186\n",
      "loss:0.09651044011116028\n",
      "loss:0.04860307648777962\n",
      "loss:0.1048612892627716\n",
      "loss:0.04861802980303764\n",
      "loss:0.07010344415903091\n",
      "loss:0.051793958991765976\n",
      "loss:0.046972889453172684\n",
      "loss:0.05206912010908127\n",
      "loss:0.060628823935985565\n",
      "loss:0.09904299676418304\n",
      "loss:0.04676412418484688\n",
      "loss:0.0530100017786026\n",
      "loss:0.05620414763689041\n",
      "loss:0.05793324485421181\n",
      "loss:0.055427830666303635\n",
      "loss:0.09919474273920059\n",
      "loss:0.054607998579740524\n",
      "loss:0.05377500504255295\n",
      "loss:0.04519793391227722\n",
      "loss:0.04638218507170677\n",
      "loss:0.050203580409288406\n",
      "loss:0.045287132263183594\n",
      "loss:0.05310916155576706\n",
      "loss:0.05863677337765694\n",
      "loss:0.05210277810692787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.08878806978464127\n",
      "loss:0.1717263013124466\n",
      "loss:0.06847652792930603\n",
      "loss:0.04384036362171173\n",
      "loss:0.047140080481767654\n",
      "loss:0.060672249644994736\n",
      "loss:0.04368949681520462\n",
      "loss:0.044839873909950256\n",
      "loss:0.043523598462343216\n",
      "loss:0.0496414378285408\n",
      "loss:0.3162239193916321\n",
      "loss:0.043275196105241776\n",
      "loss:0.05280445143580437\n",
      "loss:0.0518839955329895\n",
      "loss:0.042904410511255264\n",
      "loss:0.04555659741163254\n",
      "loss:0.049672260880470276\n",
      "loss:0.04416251927614212\n",
      "loss:0.08712614327669144\n",
      "loss:0.05570948123931885\n",
      "loss:0.05229908227920532\n",
      "loss:0.11347603797912598\n",
      "loss:0.042128197848796844\n",
      "loss:0.061556048691272736\n",
      "loss:0.055761199444532394\n",
      "loss:0.048121389001607895\n",
      "loss:0.046290747821331024\n",
      "loss:0.05886713042855263\n",
      "loss:0.05446017533540726\n",
      "loss:0.059621281921863556\n",
      "loss:0.07038373500108719\n",
      "loss:0.05576719343662262\n",
      "loss:0.04805457219481468\n",
      "loss:0.042365819215774536\n",
      "loss:0.04266088455915451\n",
      "loss:0.0414525605738163\n",
      "loss:0.04451172426342964\n",
      "loss:0.04638538882136345\n",
      "loss:0.044960279017686844\n",
      "loss:0.05126512050628662\n",
      "loss:0.05674448236823082\n",
      "loss:0.04049612581729889\n",
      "loss:0.046614035964012146\n",
      "loss:0.047392021864652634\n",
      "loss:0.04592994973063469\n",
      "loss:0.05147554352879524\n",
      "loss:0.041337091475725174\n",
      "loss:0.04167291149497032\n",
      "loss:0.05607881769537926\n",
      "loss:0.049555763602256775\n",
      "loss:0.042374785989522934\n",
      "loss:0.0397222563624382\n",
      "loss:0.039610881358385086\n",
      "loss:0.04399808868765831\n",
      "loss:0.0392117016017437\n",
      "loss:0.053918566554784775\n",
      "loss:0.05935055762529373\n",
      "loss:0.041926462203264236\n",
      "loss:0.03918271139264107\n",
      "loss:0.04105505719780922\n",
      "loss:0.0480581670999527\n",
      "loss:0.040111977607011795\n",
      "loss:0.06018729880452156\n",
      "loss:0.0770082175731659\n",
      "loss:0.05319194123148918\n",
      "loss:0.04753914847970009\n",
      "loss:0.040626559406518936\n",
      "loss:0.06265902519226074\n",
      "loss:0.043688926845788956\n",
      "loss:0.043802399188280106\n",
      "loss:0.06057678908109665\n",
      "loss:0.03747141361236572\n",
      "loss:0.04594724625349045\n",
      "loss:0.037390097975730896\n",
      "loss:0.040779959410429\n",
      "loss:0.03738488256931305\n",
      "loss:0.03711293265223503\n",
      "loss:0.044597260653972626\n",
      "loss:0.05159677937626839\n",
      "loss:0.06277403980493546\n",
      "loss:0.04828210175037384\n",
      "loss:0.03676166012883186\n",
      "loss:0.03705306723713875\n",
      "loss:0.040523067116737366\n",
      "loss:0.05761547386646271\n",
      "loss:0.06713439524173737\n",
      "loss:0.03808857500553131\n",
      "loss:0.036053214222192764\n",
      "loss:0.06248210743069649\n",
      "loss:0.0461079403758049\n",
      "loss:0.03577560558915138\n",
      "loss:0.03580385446548462\n",
      "loss:0.12738963961601257\n",
      "loss:0.04000021517276764\n",
      "loss:0.03549538925290108\n",
      "loss:0.05437637120485306\n",
      "loss:0.035386551171541214\n",
      "loss:0.05193408578634262\n",
      "loss:0.03920799493789673\n",
      "loss:0.03579755499958992\n",
      "loss:0.0351378470659256\n",
      "loss:0.05066068843007088\n",
      "loss:0.04166676476597786\n",
      "loss:0.047419119626283646\n",
      "loss:0.051094114780426025\n",
      "loss:0.050204936414957047\n",
      "loss:0.05554606392979622\n",
      "loss:0.03689887374639511\n",
      "loss:0.05338079109787941\n",
      "loss:0.03847506269812584\n",
      "loss:0.04703565314412117\n",
      "loss:0.0344417579472065\n",
      "loss:0.03690464049577713\n",
      "loss:0.045857854187488556\n",
      "loss:0.035776104778051376\n",
      "loss:0.03920220211148262\n",
      "loss:0.046585552394390106\n",
      "loss:0.04118522256612778\n",
      "loss:0.04729893431067467\n",
      "loss:0.04704699665307999\n",
      "loss:0.044367726892232895\n",
      "loss:0.04271013289690018\n",
      "loss:0.04572383314371109\n",
      "loss:0.03374071791768074\n",
      "loss:0.05189870670437813\n",
      "loss:0.04207397624850273\n",
      "loss:0.04734043776988983\n",
      "loss:0.05509236827492714\n",
      "loss:0.0383102223277092\n",
      "loss:0.041252825409173965\n",
      "loss:0.04248043894767761\n",
      "loss:0.036484237760305405\n",
      "loss:0.034015536308288574\n",
      "loss:0.03347087278962135\n",
      "loss:0.04122927412390709\n",
      "loss:0.03899400681257248\n",
      "loss:0.033217769116163254\n",
      "loss:0.03307215869426727\n",
      "loss:0.03295113518834114\n",
      "loss:0.032856740057468414\n",
      "loss:0.03267887607216835\n",
      "loss:0.03305988013744354\n",
      "loss:0.04432644322514534\n",
      "loss:0.038008738309144974\n",
      "loss:0.03226073458790779\n",
      "loss:0.040605440735816956\n",
      "loss:0.03213760256767273\n",
      "loss:0.045645128935575485\n",
      "loss:0.03654780611395836\n",
      "loss:0.04678108170628548\n",
      "loss:0.033767130225896835\n",
      "loss:0.03741233050823212\n",
      "loss:0.0593302920460701\n",
      "loss:0.059127382934093475\n",
      "loss:0.04435800388455391\n",
      "loss:0.03638427332043648\n",
      "loss:0.07655830681324005\n",
      "loss:0.046270065009593964\n",
      "loss:0.03942667320370674\n",
      "loss:0.03407403454184532\n",
      "loss:0.042766276746988297\n",
      "loss:0.08901429921388626\n",
      "loss:0.0603158064186573\n",
      "loss:0.03127554431557655\n",
      "loss:0.03687141463160515\n",
      "loss:0.048252105712890625\n",
      "loss:0.031185831874608994\n",
      "loss:0.0512014739215374\n",
      "loss:0.040157485753297806\n",
      "loss:0.0342266820371151\n",
      "loss:0.04478365555405617\n",
      "loss:0.04051916301250458\n",
      "loss:0.0317351371049881\n",
      "loss:0.035831987857818604\n",
      "loss:0.03777455538511276\n",
      "loss:0.04081564396619797\n",
      "loss:0.03146492689847946\n",
      "loss:0.03636445477604866\n",
      "loss:0.031195474788546562\n",
      "loss:0.040881022810935974\n",
      "loss:0.03973935917019844\n",
      "loss:0.06559298932552338\n",
      "loss:0.03249039128422737\n",
      "loss:0.04064051806926727\n",
      "loss:0.04017611965537071\n",
      "loss:0.032534822821617126\n",
      "loss:0.04044272005558014\n",
      "loss:0.03217659890651703\n",
      "loss:0.04134557768702507\n",
      "loss:0.037089455872774124\n",
      "loss:0.044218286871910095\n",
      "loss:0.040018048137426376\n",
      "loss:0.03830799087882042\n",
      "loss:0.08389291912317276\n",
      "loss:0.03137756511569023\n",
      "loss:0.05540774017572403\n",
      "loss:0.036294467747211456\n",
      "loss:0.06866192817687988\n",
      "loss:0.02969757653772831\n",
      "loss:0.032076671719551086\n",
      "loss:0.08966508507728577\n",
      "loss:0.04552771523594856\n",
      "loss:0.03616081178188324\n",
      "loss:0.029422461986541748\n",
      "loss:0.035528045147657394\n",
      "loss:0.02932063676416874\n",
      "loss:0.03307931125164032\n",
      "loss:0.033322740346193314\n",
      "loss:0.029357360675930977\n",
      "loss:0.08013775944709778\n",
      "loss:0.03045281395316124\n",
      "loss:0.05722701549530029\n",
      "loss:0.06540323793888092\n",
      "loss:0.029406452551484108\n",
      "loss:0.05953707918524742\n",
      "loss:0.03606640174984932\n",
      "loss:0.04399725794792175\n",
      "loss:0.031915463507175446\n",
      "loss:0.03355421870946884\n",
      "loss:0.0316336490213871\n",
      "loss:0.05012618377804756\n",
      "loss:0.037697575986385345\n",
      "loss:0.029532214626669884\n",
      "loss:0.044757988303899765\n",
      "loss:0.03821863606572151\n",
      "loss:0.074473537504673\n",
      "loss:0.029934657737612724\n",
      "loss:0.0360705740749836\n",
      "loss:0.034741420298814774\n",
      "loss:0.05378624051809311\n",
      "loss:0.03932235762476921\n",
      "loss:0.0402972586452961\n",
      "loss:0.047444961965084076\n",
      "loss:0.03464503213763237\n",
      "loss:0.04171319678425789\n",
      "loss:0.03197930380702019\n",
      "loss:0.0313081219792366\n",
      "loss:0.028228700160980225\n",
      "loss:0.03781309723854065\n",
      "loss:0.042274359613657\n",
      "loss:0.039716433733701706\n",
      "loss:0.32359471917152405\n",
      "loss:0.09853881597518921\n",
      "loss:0.029314054176211357\n",
      "loss:0.028335392475128174\n",
      "loss:0.02823297120630741\n",
      "loss:0.028083378449082375\n",
      "loss:0.031813815236091614\n",
      "loss:0.04622630402445793\n",
      "loss:0.03499944508075714\n",
      "loss:0.0409495010972023\n",
      "loss:0.027783215045928955\n",
      "loss:0.03180626779794693\n",
      "loss:0.02753288671374321\n",
      "loss:0.029914790764451027\n",
      "loss:0.030371984466910362\n",
      "loss:0.044678859412670135\n",
      "loss:0.08962097018957138\n",
      "loss:0.02795588970184326\n",
      "loss:0.027068300172686577\n",
      "loss:0.07302062213420868\n",
      "loss:0.04890315607190132\n",
      "loss:0.03175519034266472\n",
      "loss:0.03734586387872696\n",
      "loss:0.028293967247009277\n",
      "loss:0.04189379885792732\n",
      "loss:0.027324626222252846\n",
      "loss:0.0339076928794384\n",
      "loss:0.027313752099871635\n",
      "loss:0.032108332961797714\n",
      "loss:0.034585773944854736\n",
      "loss:0.048963502049446106\n",
      "loss:0.035418201237916946\n",
      "loss:0.040109727531671524\n",
      "loss:0.04342786595225334\n",
      "loss:0.035730473697185516\n",
      "loss:0.20524011552333832\n",
      "loss:0.030509961768984795\n",
      "loss:0.03418971970677376\n",
      "loss:0.028544625267386436\n",
      "loss:0.02720828168094158\n",
      "loss:0.02669653668999672\n",
      "loss:0.03306744620203972\n",
      "loss:0.06632296741008759\n",
      "loss:0.03292641416192055\n",
      "loss:0.033956170082092285\n",
      "loss:0.029316160827875137\n",
      "loss:0.03601507470011711\n",
      "loss:0.03977462276816368\n",
      "loss:0.027437860146164894\n",
      "loss:0.10143668204545975\n",
      "loss:0.03594646975398064\n",
      "loss:0.055828120559453964\n",
      "loss:0.02605682611465454\n",
      "loss:0.035687677562236786\n",
      "loss:0.02604832872748375\n",
      "loss:0.22163470089435577\n",
      "loss:0.03178933635354042\n",
      "loss:0.04182809591293335\n",
      "loss:0.03147654980421066\n",
      "loss:0.02873585931956768\n",
      "loss:0.02915705181658268\n",
      "loss:0.02792370319366455\n",
      "loss:0.03418811783194542\n",
      "loss:0.12120389938354492\n",
      "loss:0.08173373341560364\n",
      "loss:0.030577298253774643\n",
      "loss:0.04758905991911888\n",
      "loss:0.025652604177594185\n",
      "loss:0.030070172622799873\n",
      "loss:0.028581006452441216\n",
      "loss:0.027427220717072487\n",
      "loss:0.025654355064034462\n",
      "loss:0.032967906445264816\n",
      "loss:0.05609067156910896\n",
      "loss:0.02628590539097786\n",
      "loss:0.0293749812990427\n",
      "loss:0.03120913729071617\n",
      "loss:0.025512248277664185\n",
      "loss:0.025110209360718727\n",
      "loss:0.03361878916621208\n",
      "loss:0.02724338322877884\n",
      "loss:0.024927640333771706\n",
      "loss:0.03041619434952736\n",
      "loss:0.03695831075310707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.0376620851457119\n",
      "loss:0.03807871416211128\n",
      "loss:0.024675684049725533\n",
      "loss:0.03988773375749588\n",
      "loss:0.0320945642888546\n",
      "loss:0.06155632808804512\n",
      "loss:0.031036533415317535\n",
      "loss:0.025122715160250664\n",
      "loss:0.04231763631105423\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 59\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 36\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(config, model, noise_scheduler, optimizer, train_dataloader, device)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m     35\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(noise_pred, noise)\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/_tensor.py:965\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, format_spec)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Tensor:\n\u001b[0;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(format_spec)\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_spec)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02362302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(images, path, step):\n",
    "    \"\"\"Save a batch of images during training for monitoring.\"\"\"\n",
    "    images = (images / 2 + 0.5).clamp(0, 1)\n",
    "    # Convert to binary\n",
    "    images = (images > 0.5).float()\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "    # Convert to PIL image\n",
    "    grid_image = torchvision.transforms.ToPILImage()(grid)\n",
    "    grid_image = grid_image.resize((512*4, 768))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    grid_image.save(f\"{path}/sample_{step}.png\")\n",
    "\n",
    "\n",
    "def generate_images(\n",
    "        checkpoint_path,\n",
    "        image_height=768,\n",
    "        image_width=512,\n",
    "        output_dir=\"generated_images\"\n",
    "):\n",
    "    # 配置\n",
    "    config = {\n",
    "        \"image_height\": image_height,\n",
    "        \"image_width\": image_width,\n",
    "        \"sample_dir\": output_dir\n",
    "    }\n",
    "\n",
    "    # 初始化设备\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # 初始化模型\n",
    "    model = UNet2DModel(\n",
    "        sample_size=[image_height, image_width],\n",
    "        in_channels=3,\n",
    "        out_channels=3,\n",
    "        layers_per_block=1,\n",
    "        block_out_channels=(32, 64, 128),\n",
    "        down_block_types=(\n",
    "            \"DownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "        ),\n",
    "        up_block_types=(\n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "        ),\n",
    "    ).to(device)\n",
    "\n",
    "    noise_scheduler = DDPMScheduler(\n",
    "        num_train_timesteps=1000,\n",
    "        beta_start=0.0001,\n",
    "        beta_end=0.02,\n",
    "        beta_schedule=\"linear\"\n",
    "    )\n",
    "\n",
    "    # 加载checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Generate sample images\n",
    "        sample = torch.randn(4, 3, config[\"image_height\"], config[\"image_width\"]).to(device)\n",
    "        timesteps = torch.linspace(999, 0, 50).long().to(device)\n",
    "        for t in timesteps:\n",
    "            residual = model(sample, t.repeat(4), return_dict=False)[0]\n",
    "            sample = noise_scheduler.step(residual, t, sample).prev_sample\n",
    "    save_images(sample, config[\"sample_dir\"], 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f254d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "generate_images(\n",
    "        checkpoint_path=\"checkpoint_500.pt\",  # 你的checkpoint路径\n",
    "        image_height=768,\n",
    "        image_width=512,\n",
    "        output_dir=\"generated_images\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247ebfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
